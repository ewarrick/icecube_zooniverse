{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77843968",
   "metadata": {},
   "source": [
    "# Initial Data Aggregation for Name that Neutrino! #\n",
    "### Elizabeth Warrick ###\n",
    "\n",
    "This python notebook serves as a source to outline how the initial form of data aggregation for the Name that Neutrino project will appear. The input will be the classifications csv from Zooniverse and then this notebook will output a table that will hold the classification counts for each subject as well as its IceCube info. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6916b7b",
   "metadata": {},
   "source": [
    "First begin by importing necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958854d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd #reading csv into data frames\n",
    "from pandas import json_normalize\n",
    "import json #reading java strings into python dictionaries\n",
    "from IPython.display import FileLink #downloading the final csv. \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb5d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the classifications csv from Zooniverse\n",
    "ntn_classifications = 'name-that-neutrino-classifications.csv'\n",
    "#Read in that csv as a pandas data frame. \n",
    "classifications = pd.read_csv(ntn_classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff011f",
   "metadata": {},
   "source": [
    "The following cell will go through the annotations column of classifications to pick out event topology classification. \n",
    "We start by initializing an empty list and then loop through all classifications of events based on user votes. \n",
    "Then we save each row as a string, but we need to transform it into a list of dictionaries.\n",
    "The variabel \"subj_id\" takes the Zooniverse subject id of each icecube event. \n",
    "Then we loop through each element in json version of each row q, this takes each row that is a giant string and turns it into dictionaries. \n",
    "We create a new key-value pair for zooniverse id to add it as a column  in the element row. \n",
    "Then we append the element (row) to the empty list.\n",
    "Lastly, we take this list that is now full of dictionaries and put it into a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b695af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expanding JSON Fields\n",
    "#Converts JSON strings into Python dictionaries, providing access to key-value pairs.\n",
    "my_list=[] #goal is to make a list of dictionaries with new key-value pair with each dictionary individually. \n",
    "for i in range(len(classifications.annotations)):\n",
    "    q = classifications.annotations[i] #string, need to transform into list of dictionaries\n",
    "    subj_id = classifications.subject_ids[i]\n",
    "    for element in json.loads(q): #list of dictionaries, element is a dictionary. \n",
    "        element[\"id\"]=subj_id #key value pair\n",
    "        my_list.append(element) #adding new dictionaries to empty list\n",
    "\n",
    "x = pd.DataFrame.from_dict(my_list) \n",
    "#putting a dictionary into a df in this way splits it up into keys = cols and values = values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cddae1",
   "metadata": {},
   "source": [
    "This next cell takes the data frame we made above (table where each row is a different question asked to the users about a subject). We take the above data frame to extract out user classifications of events. \n",
    "\n",
    "We start by making a list of the different classes an event can be and by making an array of all the unique subject ids that have been classified . This is to help us tally up votes made by the users. \n",
    "\n",
    "We then begin building an empty data frame where the columns are the different event classes and the index is the event id of the unique events. \n",
    "\n",
    "Then we loop through the unique events in unique_events, and create a variable \"counts\" that goes through the data frame of tasks, x, and find the question where users classified the event toplogy and counts the different values for that. \n",
    "We then create an empty dictionary called \"temp_dict.\"\n",
    "Then we loop through classes to see if it appears in counts for the unique event and how many times it appears.\n",
    "For every time it appears, we create a new key-value pair of the class type and its counts. If it doesn't appear then that key-value pair is 0. \n",
    "Lastly we combine events_counts with the temp_dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c209ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Cascade\",\"Skimming\", \"Through-Going Track\", \"Starting Track\", \"Stopping Track\"]\n",
    "\n",
    "unique_events = np.unique(classifications['subject_ids'])\n",
    "\n",
    "event_counts = pd.DataFrame(columns=classes, index = unique_events)\n",
    "for event in unique_events:\n",
    "    counts = x.loc[(x[\"task\"] == 'T0') & (x[\"id\"] == event)]['value'].value_counts()\n",
    "    temp_dict = {}\n",
    "    for c in classes:\n",
    "        if c in counts.keys():\n",
    "            temp_dict[c] = counts[c] #new key-value pair\n",
    "        else: #if a type of event doesn't appear\n",
    "            temp_dict[c] = 0\n",
    "    event_counts.loc[event] = temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d947f8",
   "metadata": {},
   "source": [
    "The following cell is a similar process as above but for accessing the icecube information of a zooniverse subject. \n",
    "Again we start my initiating an empty list and a list of the different columns we want. We then build another empty data frame out of the list of column names we want. \n",
    "We start by looping through each row in the subject data column of classifications and pull out the key of each row, which is its subject id. \n",
    "We then say that if the event subject id is in the empty list to continue through the loop (this ensures that we don't have any repeat terms). \n",
    "Then if the event is not a repeat (i.e. already appended to the empty list), then we add it and create a new dictionary where the value in the key-value pair is another dictionary with the subject data column of classifications. \n",
    "Then we put that dictionary as a row and save it to the data frame icecube_info, where the key is the subject id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0866e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list2 = []\n",
    "classes2 = ['retired',\"Run\", \"Event\", 'Filename','#prediction_0000', '#prediction_0001', '#prediction_0002', '#prediction_0003','#prediction_0004']\n",
    "icecube_info = pd.DataFrame(columns=classes2)\n",
    "for i in range(len(classifications.subject_data)):\n",
    "    r = classifications.subject_data[i]\n",
    "    event2 = list(json.loads(r).keys())[0]\n",
    "    if event2 in my_list2:\n",
    "        continue\n",
    "    else:\n",
    "        my_list2.append(event2)\n",
    "        dict2 = json.loads(r)[event2] #another dictionary, value in the key-value pair is another dict. \n",
    "        icecube_info.loc[int(event2)] = dict2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916b27a",
   "metadata": {},
   "source": [
    "Lastly we join the two dataframes and create a out filename and then convert to a csv that we can export. Make sure index=True to have the subject id included in the resulting table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e65c8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = event_counts.join(icecube_info, how=\"outer\")\n",
    "filename_output = 'classifications_counts.csv'\n",
    "output.to_csv(filename_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3399a7",
   "metadata": {},
   "source": [
    "The command below allows your to download the csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdfc9efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='classifications_counts.csv' target='_blank'>classifications_counts.csv</a><br>"
      ],
      "text/plain": [
       "/Users/elizabethwarrick/Drexel/Research/IceCube/DataExportPractice/classifications_counts.csv"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(filename_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
